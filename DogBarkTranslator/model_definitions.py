# -*- coding: utf-8 -*-
"""model_definitions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h9fK2Klh1OJaHPZnyw7dna6lO5fbMDDV
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchaudio
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from io import BytesIO

# Model definition
class CNN(nn.Module):
    def __init__(self, input_channels=1, num_classes=3):
        super(CNN, self).__init__()

        # Convolutional layers
        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=16, kernel_size=3, padding="same")
        self.bn1 = nn.BatchNorm2d(16)

        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding="same")
        self.bn2 = nn.BatchNorm2d(32)

        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding="same")
        self.bn3 = nn.BatchNorm2d(64)

        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding="same")
        self.bn4 = nn.BatchNorm2d(128)

        self.dropout = nn.Dropout(p=0.5)

        # Dynamically calculate flattened size
        self.flattened_size = self.get_flattened_size((1, 1, 59, 344))
        self.linear = nn.Linear(self.flattened_size, num_classes)

    def get_flattened_size(self, input_shape):
        with torch.no_grad():
            x = torch.zeros(input_shape)
            x = self.conv1(x)
            x = self.bn1(x)
            x = F.relu(x)
            x = F.max_pool2d(x, 2)

            x = self.conv2(x)
            x = self.bn2(x)
            x = F.relu(x)
            x = F.max_pool2d(x, 2)

            x = self.conv3(x)
            x = self.bn3(x)
            x = F.relu(x)
            x = F.max_pool2d(x, 2)

            x = self.conv4(x)
            x = self.bn4(x)
            x = F.relu(x)
            x = F.max_pool2d(x, 2)

            return x.numel()

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = F.max_pool2d(x, 2)

        x = self.conv2(x)
        x = self.bn2(x)
        x = F.relu(x)
        x = F.max_pool2d(x, 2)

        x = self.conv3(x)
        x = self.bn3(x)
        x = F.relu(x)
        x = F.max_pool2d(x, 2)

        x = self.conv4(x)
        x = self.bn4(x)
        x = F.relu(x)
        x = F.max_pool2d(x, 2)

        x = self.dropout(x)
        x = torch.flatten(x, start_dim=1)
        x = self.linear(x)
        return F.softmax(x, dim=1)

# Function for loading paths into a model
# model_class is CNN
# num_classes is 3 for predict_context, 10 for predict_name, and 6 for predict_breed
def load_model(model_class, weights_path, num_classes):
    model = CNN(input_channels=1, num_classes=num_classes)
    state_dict = torch.load(weights_path, weights_only=False, map_location=torch.device("cpu"))
    model.load_state_dict(state_dict)
    model.eval()
    return model

# Creating API
'''
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
import torch
import torchaudio
from io import BytesIO
from model_definitions import Model1, load_model
'''

app = FastAPI(max_length=10 * 1024 * 1024)


# Load models
context_model = load_model(CNN, "Models_format_ipynb/weightsForContextPredict.pth", num_classes=3)
name_model = load_model(CNN, "Models_format_ipynb/weightsForNamePredict.pth", num_classes=10)
breed_model = load_model(CNN, "Models_format_ipynb/weightsForBreedPredict.pth", num_classes=6)

@app.get("/")
def root():
    return {"message": "Model API is running"}

@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    # Read the audio file
    audio_bytes = await file.read()

    # Load audio into a waveform (ensure your file is in a format supported by torchaudio)
    waveform, sample_rate = torchaudio.load(BytesIO(audio_bytes))
    print(f"Waveform shape: {waveform.shape}, Sample rate: {sample_rate}")

    # Resample if needed (example if the model expects 16000 Hz)
    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)
    waveform = resampler(waveform)
    print(f"Resampled waveform shape: {waveform.shape}")

    # Perform prediction
    with torch.no_grad():
        # Add batch dimension for models expecting it
        context_pred = context_model(waveform.unsqueeze(0))
        name_pred = name_model(waveform.unsqueeze(0))
        breed_pred = breed_model(waveform.unsqueeze(0))

        # Print model outputs before argmax
        print("Context model output:", context_pred)
        print("Name model output:", name_pred)
        print("Breed model output:", breed_pred)

        # Apply softmax and argmax to get the predicted class
        context_pred = torch.argmax(torch.nn.functional.softmax(context_pred, dim=1), dim=1).item()
        name_pred = torch.argmax(torch.nn.functional.softmax(name_pred, dim=1), dim=1).item()
        breed_pred = torch.argmax(torch.nn.functional.softmax(breed_pred, dim=1), dim=1).item()

    # Return the predictions as a JSON response
    return JSONResponse({
        "context_prediction": context_pred,
        "name_prediction": name_pred,
        "breed_prediction": breed_pred
    })




